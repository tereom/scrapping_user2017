---
title: "Scrapping useR!2017 videos"
output: html_document
---

Last week I read Dean Attali's post [What makes an R talk popular? Scraping useR2017 attendance information to find out!](What makes an R talk popular? Scraping useR2017 attendance information to find out!) and I wondered
whether the most attended talks during useR2017 are also the most viewed in recording. So I decided to do a little bit of 
web scrapping to find out, the videos are in
[Channel 9](https://channel9.msdn.com/Events/useR-international-R-User-conferences/useR-International-R-User-2017-Conference?sort=status&direction=desc&page=1) and from here I got the speakers, talks' titles, days released and views.

DISCLAIMER: I am by no means an expert in web scrapping (I had only done it once with a toy example) so
I am sure my code is not the best.

I used the [rvest](https://github.com/hadley/rvest) package and the [selector gadget](http://selectorgadget.com):

```{r scrapping_functions, message=FALSE}
library(rvest)
library(ggplot2)
library(plotly)
library(purrr)
library(dplyr)
library(printr)

videos_urls <- paste0("https://channel9.msdn.com/Events/useR-international-R-User-conferences/useR-International-R-User-2017-Conference?sort=status&direction=desc&page=", 1:16)

get_speakers <- function(talk_content){
  talk_content %>%
    html_node(".authors") %>%
    html_text(trim = TRUE) %>%
    stringr::str_replace(pattern = "by ", "")
}
get_views <- function(talk_content){
  talk_content %>%
    html_nodes(".views .count") %>%
    html_text(trim = TRUE) %>%
    as.numeric()
}
get_length <- function(talk_content){
  talk_content %>%
    html_nodes(".caption") %>%
    html_text(trim = TRUE) 
}
get_released_day <- function(talk_content){
  talk_content %>%
    html_nodes(".releaseDate") %>%
    html_text(trim = TRUE) 
}

get_info_talk <- function(talk_url, title = "No title"){ 
  # print(talk_url)
  talk_content <- read_html(talk_url) 
  views <- get_views(talk_content)
  data_frame(
    title = title,
    speakers = try(get_speakers(talk_content)),
    views = try(ifelse(length(views) > 0, views, NA)),
    day_released = try(get_released_day(talk_content))
  )
}

get_event_data <- function(video_url) {
  # Read the HTML page
  base_url <- "https://channel9.msdn.com"
  content <- read_html(video_url)
  
  # Extract information from the page
  titles <- content %>% 
    html_nodes("h3 a") %>%
    html_text(trim = TRUE)
  
  talks_urls <- content %>% 
    html_nodes("h3 a") %>%
    html_attr("href")
  talks_urls <- paste(base_url, talks_urls, sep = "")
  talks_values <- map2_df(talks_urls, titles, ~get_info_talk(.x, .y))
}

# views <- map_df(videos_urls, ~ get_event_data(.x))
# save(views, file = "views.RData")
# takes a long time to run so I saved the data frame views
load(file = "views.RData")
```

So far there are `r nrow(views)` videos in Channel 9, latest one released in
July 25. 

```{r}
glimpse(views)
```

Sort by most viewed:

```{r}
views %>%
    mutate(
        title = substr(title, 1, 40), 
        speakers = substr(speakers, 1, 20)) %>%
    arrange(desc(views)) %>%
    select(title, speakers, views) %>%
    top_n(10)
```

We can see that the most viewed are not the most attended, from [Dean Attali](http://deanattali.com/blog/user2017/) the most attended are:

1. *Show Me Your Model: tools for visualisation of statisticâ€¦*, speaker Przemyslaw Biecek 
and 519 attendees

2. *Scraping data with rvest and purrr*, speaker Max Humber 
and 362 attendees

3. *Text mining, the tidy way* speaker Julia Silge and 351 attendees, 

4. *Programming with tidyverse grammars* speaker Lionel Henry and 350 attendees, 

5. *How we built a Shiny App for 700 users?* speaker Olga Mierzwa-Sulima and 321 attendees.

Better to plot, I used Dean Attali script to scrape attendance and joined the 
resulting table with the table of recordings' views:

```{r attendance_views, message=FALSE, warning=FALSE}
# source("scrape_attendance.R")
# save(all_taks, file = "attendance.RData")
# takes some time to run so I saved the data frame all_talks
load("attendance.RData")

views_filtered <- views %>%
    arrange(desc(title)) %>%
    filter(speakers != "TBD") %>%
    mutate(
        speaker = trimws(speakers)
    )

views_attendance <- views_filtered %>%
    left_join(all_talks, by = "speaker")
```

I filtered the talks where the speaker slot had TBD, and I joined the data sets
(corresponding to attendance and views) using the speaker` columns, I tried 
to join by title but the title columns did not match for many talks. Joining by 
speaker was not perfect either I lost a few talks, I need to do it
more carefully.

```{r plotly, message=FALSE, warning=FALSE}
p <- ggplot(views_attendance) +
    geom_point(aes(x = views, y = attendance, text = title.x, color = type), alpha = 0.7) + 
    scale_x_log10() +
    scale_y_log10() +
    theme_bw() +
    labs(title = "useR2017 talks")
pp <- ggplotly(p, tooltip = c("text"), originalData = TRUE)
pp
```




I think it is interesting that the talks with the highest attendance are not 
the most popular recordings. There are several patterns, for example, the 
*Invited talks* have the highest attendance but rank relatively lower in recording views
(although still many views).
The opposite happens to talks like *Too good for your own good:Shiny prototypes 
out of control* or *Morphological Analysis with R* which had lower attendance compared
to recordings views.


